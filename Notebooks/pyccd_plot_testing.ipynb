{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "from collections import namedtuple\n",
    "import os\n",
    "import re\n",
    "import datetime as dt\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define some helper methods and data structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "GeoExtent = namedtuple('GeoExtent', ['x_min', 'y_max', 'x_max', 'y_min'])\n",
    "GeoAffine = namedtuple('GeoAffine', ['ul_x', 'x_res', 'rot_1', 'ul_y', 'rot_2', 'y_res'])\n",
    "GeoCoordinate = namedtuple('GeoCoordinate', ['x', 'y'])\n",
    "RowColumn = namedtuple('RowColumn', ['row', 'column'])\n",
    "RowColumnExtent = namedtuple('RowColumnExtent', ['start_row', 'start_col', 'end_row', 'end_col'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def geospatial_hv(h, v, loc):\n",
    "    \"\"\"\n",
    "    Geospatial extent and 30m affine for a given ARD grid location.\n",
    "    \"\"\"\n",
    "    xmin = loc.x_min + h * 5000 * 30\n",
    "    xmax = loc.x_min + h * 5000 * 30 + 5000 * 30\n",
    "    ymax = loc.y_max - v * 5000 * 30\n",
    "    ymin = loc.y_max - v * 5000 * 30 - 5000 * 30\n",
    "\n",
    "    return (GeoExtent(x_min=xmin, x_max=xmax, y_max=ymax, y_min=ymin),\n",
    "            GeoAffine(ul_x=xmin, x_res=30, rot_1=0, ul_y=ymax, rot_2=0, y_res=-30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def geo_to_rowcol(affine, coord):\n",
    "    \"\"\"\n",
    "    Transform geo-coordinate to row/col given a reference affine.\n",
    "    \n",
    "    Yline = (Ygeo - GT(3) - Xpixel*GT(4)) / GT(5)\n",
    "    Xpixel = (Xgeo - GT(0) - Yline*GT(2)) / GT(1)\n",
    "    \"\"\"\n",
    "    row = (coord.y - affine.ul_y - affine.ul_x * affine.rot_2) / affine.y_res\n",
    "    col = (coord.x - affine.ul_x - affine.ul_y * affine.rot_1) / affine.x_res\n",
    "\n",
    "    return RowColumn(row=int(row),\n",
    "                     column=int(col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rowcol_to_geo(affine, rowcol):\n",
    "    \"\"\"\n",
    "    Transform a row/col into a geospatial coordinate given reference affine.\n",
    "    \n",
    "    Xgeo = GT(0) + Xpixel*GT(1) + Yline*GT(2)\n",
    "    Ygeo = GT(3) + Xpixel*GT(4) + Yline*GT(5)\n",
    "    \"\"\"\n",
    "    x = affine.ul_x + rowcol.column * affine.x_res + rowcol.row * affine.rot_1\n",
    "    y = affine.ul_y + rowcol.column * affine.rot_2 + rowcol.row * affine.y_res\n",
    "\n",
    "    return GeoCoordinate(x=x, y=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_cache(file):\n",
    "    \"\"\"\n",
    "    Load the cache file and split the data into the image IDs and values\n",
    "    \"\"\"\n",
    "    data = np.load(file)\n",
    "    return data['Y'], data['image_IDs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_file(file_ls, string):\n",
    "    \"\"\"\n",
    "    Return the first str in a list of strings that contains string.\n",
    "    \"\"\"\n",
    "    gen = filter(lambda x: string in x, file_ls)\n",
    "    return next(gen, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def imageid_date(image_ids):\n",
    "    \"\"\"\n",
    "    Extract the ordinal day from the ARD image name.\n",
    "    \"\"\"\n",
    "    return np.array([dt.datetime.strptime(d[15:23], '%Y%m%d').toordinal()\n",
    "                     for d in image_ids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mask_daterange(dates):\n",
    "    \"\"\"\n",
    "    Create a mask for values outside of the global BEGIN_DATE and END_DATE.\n",
    "    \"\"\"\n",
    "    mask = np.zeros_like(dates, dtype=bool)\n",
    "    \n",
    "    mask = np.logical_and(dates >= BEGIN_DATE.toordinal(), dates <= END_DATE.toordinal())\n",
    "    \n",
    "    # mask[(dates >= BEGIN_DATE.toordinal()) & (dates <= END_DATE.toordinal())] = 1\n",
    "\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mask_daterange_edit(dates):\n",
    "    \"\"\"\n",
    "    Create a mask for values outside of the global BEGIN_DATE and END_DATE.\n",
    "    Create a similar mask for values inside of these global values.\n",
    "    \"\"\"\n",
    "    mask_in = np.zeros_like(dates, dtype=bool)\n",
    "    mask_out = np.copy(mask_in)\n",
    "    \n",
    "    mask_in = np.logical_and(dates >= BEGIN_DATE.toordinal(), dates <= END_DATE.toordinal())\n",
    "    \n",
    "    # mask_in[dates >= BEGIN_DATE.toordinal() & (dates <= END_DATE.toordinal())] = 1\n",
    "    \n",
    "    mask_out = np.logical_or(dates < BEGIN_DATE.toordinal(), dates > END_DATE.toordinal())\n",
    "    \n",
    "    # mask_out[(dates < BEGIN_DATE.toordinal()) | (dates > END_DATE.toordinal())] = 1\n",
    "\n",
    "    return mask_in, mask_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_chipcurve(results_chip, coord):\n",
    "    \"\"\"\n",
    "    Find the results for the specified coordinate.\n",
    "    \"\"\"\n",
    "    with open(results_chip, 'r') as f:\n",
    "        results = json.load(f)\n",
    "    \n",
    "    gen = filter(lambda x: coord.x == x['x'] and coord.y == x['y'], results)\n",
    "    \n",
    "    return next(gen, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_cachepoint(coord):\n",
    "    \"\"\"\n",
    "    Extract the spectral values from the cache file.\n",
    "    \"\"\"\n",
    "\n",
    "    rowcol = geo_to_rowcol(PIXEL_AFFINE, coord)\n",
    "    \n",
    "    data, image_ids = load_cache(find_file(CACHE_INV, 'r{}'.format(rowcol.row)))\n",
    "    \n",
    "    dates = imageid_date(image_ids)\n",
    "        \n",
    "    # mask = mask_daterange(dates)\n",
    "    \n",
    "    return image_ids, data[:, :, rowcol.column], dates\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_cachepoint_edit(coord):\n",
    "    \"\"\"\n",
    "    Extract the spectral values from the cache file.\n",
    "    \"\"\"\n",
    "\n",
    "    rowcol = geo_to_rowcol(PIXEL_AFFINE, coord)\n",
    "    \n",
    "    data, image_ids = load_cache(find_file(CACHE_INV, 'r{}'.format(rowcol.row)))\n",
    "    \n",
    "    dates = imageid_date(image_ids)\n",
    "    \n",
    "    # Duplicate dates removed\n",
    "    dates_, indices = np.unique(dates, return_index=True)\n",
    "    \n",
    "    data_ = data[:, indices]\n",
    "    \n",
    "    mask_in, mask_out = mask_daterange_edit(dates_)\n",
    "    \n",
    "    \n",
    "    return image_ids, data[:, mask, rowcol.column], dates[mask], mask_in, mask_out\n",
    "    \n",
    "    \"\"\"\n",
    "    # Check if the len of the processing mask equals the len of dates with duplicates removed\n",
    "    # For most cases the length of the internal processing mask should be equal to the \n",
    "    # number of observations within the BEGIN and END date range\n",
    "    \n",
    "    if len(results) == len(dates_[mask_in]):\n",
    "\n",
    "        print(\"The length of the pyccd internal processing mask ({}) is consistent with the number of observations\"\n",
    "              \" in the cache files ({}) with duplicate dates removed\".format(len(results),\n",
    "                                                                             len(dates_[mask_in])))\n",
    "\n",
    "        # mask_in, mask_out = mask_daterange(dates_)\n",
    "\n",
    "        return image_ids, data_[:, mask_in, rowcol.column], dates_[mask_in], \\\n",
    "               data_[:, mask_out, rowcol.column], dates_[mask_out]\n",
    "\n",
    "    elif len(results) != len(dates_[mask_in]):\n",
    "\n",
    "        mask_in, mask_out = self.mask_daterange_edit(dates)\n",
    "\n",
    "        if len(results) == len(dates[mask_in]):\n",
    "\n",
    "            print(\"The length of the pyccd internal processing mask ({}) is consistent with the \"\n",
    "                  \"number of observations in the cache files ({}) if duplicate dates are not \"\n",
    "                  \"removed\".format(len(results), len(dates[mask_in])))\n",
    "\n",
    "            return image_ids, data[:, mask_in, rowcol.column], dates[mask_in], \\\n",
    "                   data[:, mask_out, rowcol.column], dates[mask_out]\n",
    "\n",
    "        else:\n",
    "\n",
    "            print(\"The length of the pyccd internal processing mask ({}) is inconsistent with\"\n",
    "                  \" the number of observations provided in the cache files ({})\".format(len(results),\n",
    "                                                                                        len(dates[mask_in])))\n",
    "\n",
    "            sys.exit(1)\n",
    "\n",
    "    return None\n",
    "    \"\"\"\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_jsoncurve(coord):\n",
    "    \"\"\"\n",
    "    Extract the pyccd information from the json file representing a chip of results.\n",
    "    \"\"\"\n",
    "    pixel_rowcol = geo_to_rowcol(PIXEL_AFFINE, coord)\n",
    "    pixel_coord = rowcol_to_geo(PIXEL_AFFINE, pixel_rowcol)\n",
    "    \n",
    "    chip_rowcol = geo_to_rowcol(CHIP_AFFINE, coord)\n",
    "    chip_coord = rowcol_to_geo(CHIP_AFFINE, chip_rowcol)\n",
    "    \n",
    "    file = find_file(JSON_INV, 'H{:02d}V{:02d}_{}_{}.json'.format(H, V, chip_coord.x, chip_coord.y))\n",
    "    result = find_chipcurve(file, pixel_coord)\n",
    "    \n",
    "    if result.get('result_ok') is True:\n",
    "        return json.loads(result['result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predicts(days, coef, intercept):\n",
    "    return (intercept + coef[0] * days +\n",
    "            coef[1]*np.cos(days*1*2*np.pi/365.25) + coef[2]*np.sin(days*1*2*np.pi/365.25) +\n",
    "            coef[3]*np.cos(days*2*2*np.pi/365.25) + coef[4]*np.sin(days*2*2*np.pi/365.25) +\n",
    "            coef[5]*np.cos(days*3*2*np.pi/365.25) + coef[6]*np.sin(days*3*2*np.pi/365.25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def arcpaste_to_coord(string):\n",
    "    pieces = string.split()\n",
    "    \n",
    "    return GeoCoordinate(x=float(re.sub(',', '', pieces[0])),\n",
    "                         y=float(re.sub(',', '', pieces[1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup file locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "JSON_DIR = r'Z:\\sites\\sd\\pyccd-results\\H13V06\\2017.08.18\\json'\n",
    "JSON_INV = [os.path.join(JSON_DIR, f) for f in os.listdir(JSON_DIR)]\n",
    "CACHE_DIR = r'Z:\\sites\\sd\\ARD\\h13v06\\cache'\n",
    "CACHE_INV = [os.path.join(CACHE_DIR, f) for f in os.listdir(CACHE_DIR)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "arc_paste = '-549,940.134  2,350,557.910 Meters'\n",
    "coord = arcpaste_to_coord(arc_paste)\n",
    "\n",
    "CONUS_EXTENT = GeoExtent(x_min=-2565585,\n",
    "                         y_min=14805,\n",
    "                         x_max=2384415,\n",
    "                         y_max=3314805)\n",
    "\n",
    "H = 13\n",
    "V = 6\n",
    "EXTENT, PIXEL_AFFINE = geospatial_hv(H, V, CONUS_EXTENT)\n",
    "CHIP_AFFINE = GeoAffine(ul_x=PIXEL_AFFINE.ul_x, x_res=3000, rot_1=0, ul_y=PIXEL_AFFINE.ul_y, rot_2=0, y_res=-3000)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = extract_jsoncurve(coord)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BEGIN_DATE = dt.datetime.fromordinal(results[\"change_models\"][0][\"start_day\"])\n",
    "END_DATE = dt.datetime.fromordinal(results[\"change_models\"][-1][\"end_day\"])\n",
    "\n",
    "print(BEGIN_DATE, END_DATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imageIDs, data, dates = extract_cachepoint(coord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# rescale the brightness temperature to match the predicted values\n",
    "temp_thermal_data = np.copy(data[6])\n",
    "temp_thermal_data[ temp_thermal_data != -9999 ] = temp_thermal_data[ temp_thermal_data != -9999 ] * 10 - 27315\n",
    "data[6] = np.copy(temp_thermal_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup geospatial and temporal information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.shape(dates))\n",
    "print(len(results[\"processing_mask\"]))\n",
    "\n",
    "date_mask = mask_daterange(dates=dates)\n",
    "dates_masked = dates[date_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(dates_masked))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(BEGIN_DATE, END_DATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(results.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(len(results[\"processing_mask\"]), len(results[\"change_models\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(len(dates), len(data[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "qa = data[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make a mask based on the ARD QA band to remove fill (value 1)\n",
    "qa_mask = np.ones_like(qa, dtype=np.bool)\n",
    "qa_mask[qa == 1] = False\n",
    "qa_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def msavi(R, NIR):\n",
    "    # Modified Soil Adjusted Vegetation Index\n",
    "    \n",
    "    return (2.0 * NIR + 1.0 - ((2.0 * NIR + 1.0)**2.0 - 8.0 * (NIR - R))**0.5) / 2.0\n",
    "\n",
    "def ndvi(R, NIR):\n",
    "    # Normalized Difference Vegetation Index\n",
    "    \n",
    "    return (NIR - R) / (NIR + R)\n",
    "\n",
    "def evi(B, R, NIR, G=2.5, L=1.0, C1=6, C2=7.5):\n",
    "    # Enhanced Vegetation Index\n",
    "    \n",
    "    return G * ((NIR - R) / (NIR + C1 * R - C2 * B + L))\n",
    "\n",
    "def savi(R, NIR, L=0.5):\n",
    "    # Soil Adjusted Vegetation Index\n",
    "    \n",
    "    return ((NIR - R) / (NIR + R + L)) * (1 + L)\n",
    "\n",
    "def ndmi(NIR, SWIR1):\n",
    "    # Normalized Difference Moisture Index\n",
    "    \n",
    "    return (NIR - SWIR1) / (NIR + SWIR1)\n",
    "\n",
    "def nbr(NIR, SWIR2):\n",
    "    # Normalized Burn Ratio\n",
    "    \n",
    "    return (NIR - SWIR2) / (NIR + SWIR2)\n",
    "\n",
    "def nbr2(SWIR1, SWIR2):\n",
    "    # Normalized Burn Ratio 2\n",
    "    \n",
    "    return (SWIR1 - SWIR2) / (SWIR1 + SWIR2)  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bands = ('blue', 'green', 'red', 'nir', 'swir1', 'swir2', 'thermal')\n",
    "band_info = {b: {'coefs': [], 'inter': [], 'pred': []} for b in bands}\n",
    "\n",
    "#mask = np.array(results['processing_mask'], dtype=bool)\n",
    "mask = np.ones_like(dates, dtype=bool)\n",
    "mask[: len(results[\"processing_mask\"])] = results[\"processing_mask\"]\n",
    "\n",
    "\"\"\"\n",
    "print('Start Date: {0}\\nEnd Date: {1}\\n'.format(dt.datetime.fromordinal(dates[0]),\n",
    "                                                dt.datetime.fromordinal(dates[-1])))\n",
    "\"\"\"\n",
    "\n",
    "predicted_values = []\n",
    "prediction_dates = []\n",
    "break_dates = []\n",
    "start_dates = []\n",
    "\n",
    "# get year values for labeling plots\n",
    "year1 = str(dt.datetime.fromordinal(dates[0]))[:4]\n",
    "year2 = str(dt.datetime.fromordinal(dates[-1]))[:4]\n",
    "years = np.arange(int(year1), int(year2), 2)\n",
    "\n",
    "for num, result in enumerate(results['change_models']):\n",
    "    print('Result: {}'.format(num))\n",
    "    print('Start Date: {}'.format(dt.date.fromordinal(result['start_day'])))\n",
    "    print('End Date: {}'.format(dt.date.fromordinal(result['end_day'])))\n",
    "    print('Break Date: {}'.format(dt.date.fromordinal(result['break_day'])))\n",
    "    print('QA: {}'.format(result['curve_qa']))\n",
    "    print('Change prob: {}'.format(result['change_probability']))\n",
    "    \n",
    "    days = np.arange(result['start_day'], result['end_day'] + 1)\n",
    "    # prediction_dates.append(days)\n",
    "    break_dates.append(result['break_day'])\n",
    "    start_dates.append(result['start_day'])\n",
    "    \n",
    "    for b in bands:\n",
    "        band_info[b]['inter'] = result[b]['intercept']\n",
    "        band_info[b]['coefs'] = result[b]['coefficients']\n",
    "        band_info[b]['pred'] = predicts(days, result[b]['coefficients'], result[b]['intercept'])\n",
    "    \n",
    "        intercept = result[b]['intercept']\n",
    "        coef = result[b]['coefficients']\n",
    "        prediction_dates.append(days)\n",
    "        predicted_values.append(predicts(days, coef, intercept))\n",
    "    \n",
    "\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "\n",
    "qa = np.copy(data[7,:])\n",
    "maskqa = np.ones_like(qa, dtype=bool)\n",
    "maskqa[ qa == 1 ] = False\n",
    "\n",
    "maskqa = maskqa[mask]\n",
    "\n",
    "dates_plt = dates[mask]\n",
    "\n",
    "# ****X-Axis Ticks and Labels****\n",
    "# list of years\n",
    "y = [yi for yi in range(1981, 2018, 2)]\n",
    "\n",
    "# list of datetime objects with YYYY-MM-dd pattern\n",
    "t = [dt.datetime(yx, 7, 1) for yx in y]\n",
    "\n",
    "# list of ordinal time objects\n",
    "ord_time = [dt.datetime.toordinal(tx) for tx in t]\n",
    "\n",
    "# list of datetime formatted strings\n",
    "x_labels = [str(dt.datetime.fromordinal(int(L)))[:10] if L != \"0.0\" and L != \"\" else \"0\" for L in ord_time]\n",
    "\n",
    "\n",
    "for num, b in enumerate(bands):\n",
    "    fg = plt.figure(figsize=(16,9), dpi=300)\n",
    "    a1 = fg.add_subplot(2, 1, 1, xlim=(min(dates)-100, max(dates)+500), ylim=(-1000,5000))\n",
    "    \n",
    "    \n",
    "    data_plt = data[num, mask]\n",
    "    \n",
    "    # Observed values\n",
    "    a1.plot(dates_plt[maskqa], data_plt[maskqa], 'go', ms=7, mec='k', mew=0.5) \n",
    "    \n",
    "    # Observed values masked out\n",
    "    a1.plot(dates[~mask], data[num, ~mask], color=\"0.65\", marker=\"o\", linewidth=0, ms=3)\n",
    "    \n",
    "    a1.set_title('Band {}'.format(str(num+1)))\n",
    "    \n",
    "    # plot model break and start dates\n",
    "    for b in break_dates: a1.axvline(b, color='r')\n",
    "    for s in start_dates: a1.axvline(s, color='b')\n",
    "    \n",
    "    # Predicted curves\n",
    "    for c in range(0 , len(results[\"change_models\"])):\n",
    "        a1.plot(prediction_dates[c * len(bands) + num], predicted_values[c * len(bands) + num],\n",
    "               \"orange\", linewidth=2)\n",
    "\n",
    "    # Add x-ticks and x-tick_labels \n",
    "    a1.set_xticks(ord_time)\n",
    "\n",
    "    a1.set_xticklabels(x_labels, rotation=70, horizontalalignment=\"right\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plot all observations\n",
    "NDVI_all = (data[3] - data[2]) / (data[3] + data[2])\n",
    "fg = plt.figure(figsize=(16,9), dpi=300)\n",
    "a1 = fg.add_subplot(2, 1, 1)\n",
    "a1.set_xticks(ord_time)\n",
    "\n",
    "a1.set_xticklabels(x_labels, rotation=70, horizontalalignment=\"right\")\n",
    "\n",
    "# don't plot values where NDVI=0\n",
    "a1.plot(dates[NDVI_all!=0], NDVI_all[NDVI_all!=0], marker=\"o\", linewidth=0, mec=\"k\", mew=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot NDVI clear observations\n",
    "BAND3 = data[2, mask]\n",
    "BAND4 = data[3, mask]\n",
    "NDVI = (BAND4 - BAND3) / (BAND3 + BAND4)\n",
    "\n",
    "fg = plt.figure(figsize=(16,9), dpi=300)\n",
    "a1 = fg.add_subplot(2,1,1)\n",
    "\n",
    "# ****X-Axis Ticks and Labels****\n",
    "# list of years\n",
    "# y = [yi for yi in range(1981, 2018, 2)]\n",
    "\n",
    "# get year values for labeling plots\n",
    "year1 = str(dt.datetime.fromordinal(dates[0]))[:4]\n",
    "year2 = str(dt.datetime.fromordinal(dates[-1]))[:4]\n",
    "years = np.arange(int(year1), int(year2) + 2, 2)\n",
    "\n",
    "# list of datetime objects with YYYY-MM-dd pattern\n",
    "t = [dt.datetime(yx, 7, 1) for yx in years]\n",
    "\n",
    "# list of ordinal time objects\n",
    "ord_time = [dt.datetime.toordinal(tx) for tx in t]\n",
    "\n",
    "# list of datetime formatted strings\n",
    "x_labels = [str(dt.datetime.fromordinal(int(L)))[:10] if L != \"0.0\" and L != \"\" else \"0\" for L in ord_time]\n",
    "\n",
    "a1.set_xticks(ord_time)\n",
    "a1.set_xticklabels(x_labels, rotation=70, horizontalalignment=\"right\")\n",
    "\n",
    "a1.plot(dates[mask], NDVI,  marker=\"o\", linewidth=0, mec=\"k\", mew=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot NDVI clear observations\n",
    "BAND3 = data[2, mask]\n",
    "BAND4 = data[3, mask]\n",
    "NDVI = (BAND4 - BAND3) / (BAND3 + BAND4)\n",
    "\n",
    "fg = plt.figure(figsize=(16,9), dpi=300)\n",
    "a1 = fg.add_subplot(2,1,1)\n",
    "\n",
    "# ****X-Axis Ticks and Labels****\n",
    "# list of years generated with static values, I think I prefer the method above that allows for different scenarios of end years\n",
    "y = [yi for yi in range(1981, 2018, 2)]\n",
    "\n",
    "# list of datetime objects with YYYY-MM-dd pattern\n",
    "t = [dt.datetime(yx, 7, 1) for yx in y]\n",
    "\n",
    "# list of ordinal time objects\n",
    "ord_time = [dt.datetime.toordinal(tx) for tx in t]\n",
    "\n",
    "# list of datetime formatted strings\n",
    "x_labels = [str(dt.datetime.fromordinal(int(L)))[:10] if L != \"0.0\" and L != \"\" else \"0\" for L in ord_time]\n",
    "\n",
    "a1.set_xticks(ord_time)\n",
    "a1.set_xticklabels(x_labels, rotation=70, horizontalalignment=\"right\")\n",
    "\n",
    "a1.plot(dates[mask], NDVI,  marker=\"o\", linewidth=0, mec=\"k\", mew=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# calculate the predicted NDVI from PyCCD change models\n",
    "\n",
    "# for c in range(0 , len(results[\"change_models\"])):\n",
    "    \n",
    "    #NDVI_pred.append((predicted_values[c * len(bands) + 3] - predicted_values[c * len(bands) + 2]) / \\\n",
    "    #(predicted_values[c * len(bands) + 3] + predicted_values[c * len(bands) + 2]))\n",
    "    \n",
    "\n",
    "# using list comprehensions\n",
    "numerator = [(predicted_values[c * len(bands) + 3] - predicted_values[c * len(bands) + 2]) for c in range(0 , len(results[\"change_models\"]))]\n",
    "\n",
    "denominator = [(predicted_values[c * len(bands) + 3] + predicted_values[c * len(bands) + 2]) for c in range(0 , len(results[\"change_models\"]))]\n",
    "\n",
    "NDVI_pred = [numerator[c] / denominator[c]  for c in range(0 , len(results[\"change_models\"])) if not np.any(denominator[c] == 0)]\n",
    "    \n",
    "# Enforce NDVI value range -1 to 1\n",
    "#for ndvi in NDVI_pred:\n",
    "#    for index, val in enumerate(ndvi):\n",
    "#        if val > 1.0: ndvi[index] = 1.0\n",
    "            \n",
    "#        elif val < -1.0: ndvi[index] = -1.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fg = plt.figure(figsize=(16,9), dpi=300 )\n",
    "a1 = fg.add_subplot(2,1,1, ylim=(-1.10, 1.10))\n",
    "\n",
    "# ****X-Axis Ticks and Labels****\n",
    "# y = [yi for yi in range(1981, 2018, 2)]\n",
    "\n",
    "# get year values for labeling plots\n",
    "year1 = str(dt.datetime.fromordinal(dates[0]))[:4]\n",
    "year2 = str(dt.datetime.fromordinal(dates[-1]))[:4]\n",
    "years = np.arange(int(year1), int(year2) + 2, 2)\n",
    "\n",
    "# list of datetime objects with YYYY-MM-dd pattern\n",
    "t = [dt.datetime(yx, 7, 1) for yx in years]\n",
    "\n",
    "# list of ordinal time objects\n",
    "ord_time = [dt.datetime.toordinal(tx) for tx in t]\n",
    "\n",
    "# list of datetime formatted strings\n",
    "x_labels = [str(dt.datetime.fromordinal(int(L)))[:10] if L != \"0.0\" and L != \"\" else \"0\" for L in ord_time]\n",
    "\n",
    "a1.set_title(\"NDVI\")\n",
    "\n",
    "a1.set_xticks(ord_time)\n",
    "a1.set_xticklabels(x_labels, rotation=70, horizontalalignment=\"right\")\n",
    "\n",
    "\n",
    "a1.plot(dates[NDVI_all!=0], NDVI_all[NDVI_all!=0], color=\"0.65\", marker=\"o\", linewidth=0, ms = 3)\n",
    "a1.plot(dates[mask], NDVI,  marker=\"o\", color=\"green\",linewidth=0, mec=\"k\", mew=0.3)\n",
    "\n",
    "# plot model break and start dates\n",
    "for b in break_dates: a1.axvline(b, color='r')\n",
    "for s in start_dates: a1.axvline(s, color='b')\n",
    "    \n",
    "for c in range(0, len(results[\"change_models\"])):\n",
    "    t1 = NDVI_pred[c] >= -1.0\n",
    "    t2 = NDVI_pred[c] <= 1.0\n",
    "    tt = (t1==True) == t2\n",
    "    a1.plot(prediction_dates[c*len(bands)][tt], NDVI_pred[c][tt],\"orange\", linewidth=2)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "EVI_pred = [2.5 * ((predicted_values[c * len(bands) + 3] - predicted_values[c * len(bands) + 2]) / \n",
    "                  (predicted_values[c * len(bands) + 3] + 6 * predicted_values[c * len(bands) + 2] - 7.5 *\n",
    "                  predicted_values[c * len(bands)] + 1)) for c in range(0, len(results[\"change_models\"]))]\n",
    "\n",
    "# Plot EVI for clear observations with PyCCD curve\n",
    "EVI_all = 2.5 * ((data[3] - data[2]) / (data[3] + 6 * data[2] - 7.5 * data[0] + 1))\n",
    "\n",
    "# Get the band 1 clear observations (already have band 3 and 4 from above)\n",
    "BAND1 = data[0, mask]\n",
    "\n",
    "EVI = 2.5 * ((BAND4 - BAND3) / (BAND4 + 6 * BAND3 - 7.5 * BAND1 + 1))\n",
    "\n",
    "for ind, e in enumerate(EVI_all):\n",
    "    if e > 1.0: EVI_all[ind] = 0\n",
    "    elif e < -1.0: EVI_all[ind] = 0\n",
    "        \n",
    "for ind, e in enumerate(EVI):\n",
    "    if e > 1.0: EVI[ind] = 0\n",
    "    elif e < -1.0: EVI[ind] = 0\n",
    "        \n",
    "# Enforce EVI value range -1 to 1\n",
    "# for evi in EVI_pred:\n",
    "#    for index, val in enumerate(evi):\n",
    "#        if val > 1.0: evi[index] = 1.0\n",
    "            \n",
    "#        elif val < -1.0: evi[index] = -1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fg = plt.figure(figsize=(16,9), dpi=300)\n",
    "a1 = fg.add_subplot(2,1,1, ylim=(-1.1, 1.1))\n",
    "\n",
    "# ****X-Axis Ticks and Labels****\n",
    "# y = [yi for yi in range(1981, 2018, 2)]\n",
    "\n",
    "# get year values for labeling plots\n",
    "year1 = str(dt.datetime.fromordinal(dates[0]))[:4]\n",
    "year2 = str(dt.datetime.fromordinal(dates[-1]))[:4]\n",
    "years = np.arange(int(year1), int(year2) + 2, 2)\n",
    "\n",
    "# list of datetime objects with YYYY-MM-dd pattern\n",
    "t = [dt.datetime(yx, 7, 1) for yx in years]\n",
    "\n",
    "# list of ordinal time objects\n",
    "ord_time = [dt.datetime.toordinal(tx) for tx in t]\n",
    "\n",
    "# list of datetime formatted strings\n",
    "x_labels = [str(dt.datetime.fromordinal(int(L)))[:10] if L != \"0.0\" and L != \"\" else \"0\" for L in ord_time]\n",
    "\n",
    "a1.set_title(\"EVI\")\n",
    "\n",
    "a1.set_xticks(ord_time)\n",
    "a1.set_xticklabels(x_labels, rotation=70, horizontalalignment=\"right\")\n",
    "\n",
    "a1.plot(dates[~mask][EVI_all[~mask] != 0], EVI_all[~mask][EVI_all[~mask] != 0], color=\"0.65\", marker=\"o\", linewidth=0, ms=3)\n",
    "a1.plot(dates[mask][EVI !=0], EVI[EVI!=0],  marker=\"o\", color=\"green\",linewidth=0, mec=\"k\", mew=0.3)\n",
    "\n",
    "# plot model break and start dates\n",
    "for b in break_dates: a1.axvline(b, color='r')\n",
    "for s in start_dates: a1.axvline(s, color='b')\n",
    "\n",
    "for c in range(0, len(results[\"change_models\"])):\n",
    "    t1 = EVI_pred[c] >= -1.0\n",
    "    t2 = EVI_pred[c] <= 1.0\n",
    "    tt = (t1==True) == t2\n",
    "    a1.plot(prediction_dates[c*len(bands)][tt], EVI_pred[c][tt] ,\"orange\", linewidth=2)\n",
    "    #a1.plot(prediction_dates[c*len(bands)], EVI_pred[c] , linewidth=2)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SAVI_pred = [savi(R=predicted_values[c * len(bands) + 3], NIR=predicted_values[c * len(bands) + 2]) \n",
    "            for c in range(0, len(results[\"change_models\"]))]\n",
    "\n",
    "SAVI_all = savi(R=data[2], NIR=data[3])\n",
    "\n",
    "SAVI_clear = savi(R=BAND3, NIR=BAND4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fg = plt.figure(figsize=(16,9), dpi=300)\n",
    "a1 = fg.add_subplot(2,1,1, ylim=(-1.1, 1.1))\n",
    "\n",
    "# ****X-Axis Ticks and Labels****\n",
    "# y = [yi for yi in range(1981, 2018, 2)]\n",
    "\n",
    "# get year values for labeling plots\n",
    "year1 = str(dt.datetime.fromordinal(dates[0]))[:4]\n",
    "year2 = str(dt.datetime.fromordinal(dates[-1]))[:4]\n",
    "years = np.arange(int(year1), int(year2) + 2, 2)\n",
    "\n",
    "# list of datetime objects with YYYY-MM-dd pattern\n",
    "t = [dt.datetime(yx, 7, 1) for yx in years]\n",
    "\n",
    "# list of ordinal time objects\n",
    "ord_time = [dt.datetime.toordinal(tx) for tx in t]\n",
    "\n",
    "# list of datetime formatted strings\n",
    "x_labels = [str(dt.datetime.fromordinal(int(L)))[:10] if L != \"0.0\" and L != \"\" else \"0\" for L in ord_time]\n",
    "\n",
    "a1.set_title(\"SAVI\")\n",
    "\n",
    "a1.set_xticks(ord_time)\n",
    "a1.set_xticklabels(x_labels, rotation=70, horizontalalignment=\"right\")\n",
    "\n",
    "a1.plot(dates[~mask][SAVI_all[~mask] != 0], SAVI_all[~mask][SAVI_all[~mask] != 0], color=\"0.65\", marker=\"o\", linewidth=0, ms=3)\n",
    "a1.plot(dates[mask], SAVI,  marker=\"o\", color=\"green\",linewidth=0, mec=\"k\", mew=0.3)\n",
    "\n",
    "# plot model break and start dates\n",
    "for b in break_dates: a1.axvline(b, color='r')\n",
    "for s in start_dates: a1.axvline(s, color='b')\n",
    "\n",
    "for c in range(0, len(results[\"change_models\"])):\n",
    "    t1 = SAVI_pred[c] >= -1.0\n",
    "    t2 = SAVI_pred[c] <= 1.0\n",
    "    tt = (t1==True) == t2\n",
    "    a1.plot(prediction_dates[c*len(bands)][tt], SAVI_pred[c][tt] ,\"orange\", linewidth=2)\n",
    "    #a1.plot(prediction_dates[c*len(bands)], SAVI_pred[c] , linewidth=2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot MSAVI for clear observations with predicted MSAVI\n",
    "\n",
    "MSAVI_pred = [msavi(R=predicted_values[c * len(bands) + 2], NIR=predicted_values[c * len(bands) + 3]) for c in range(0, len(results[\"change_models\"]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MSAVI_clear = msavi(R=BAND4, NIR=BAND3)\n",
    "print(len(MSAVI_clear))\n",
    "MSAVI_all = msavi(data[3, ~mask], data[2, ~mask])\n",
    "print(len(MSAVI_all))\n",
    "print(len(mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# datesYMD = [str(dt.datetime.fromordinal(d))[:10] for d in dates]\n",
    "# datesYMD=[d.replace(\"-\",\"\") for d in datesYMD]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#for i, j in zip(imageIDs, datesYMD):\n",
    "   # if i[15:23] != (j): print(i , j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# len(imageIDs), len(datesYMD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#np.shape(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#qa = np.copy(data[7,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#np.shape(qa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#np.amin(qa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#np.amax(qa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#qa_vals = [(a, \":\", bin(a)) for a in np.unique(qa)]\n",
    "#for q in qa_vals: print(q,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
